{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "529d38c0-106a-48b3-af27-a03faf2fa7f8",
   "metadata": {
    "tags": [
     "dataset/nyc-taxi",
     "library/dask",
     "tools/dask-kubernetes",
     "library/cuml",
     "library/xgboost",
     "cloud/gcp/gke",
     "platform/kubernetes",
     "library/cudf",
     "workflow/benchmarks"
    ]
   },
   "source": [
    "# Exploring multi-node cuML performance with Dask on Google Cloud\n",
    "\n",
    "In this notebook we are going to launch a RAPIDS cluster on Google Cloud with Kubernetes and Dask and then do some performance comparisons.\n",
    "\n",
    "First we will load some Parquet and CSV data and explore the perforance differences between those file formats.\n",
    "\n",
    "Then we will run through various cuML algorythms and explore their performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7cb8a84-3f4a-4776-ba29-d91acf7dda03",
   "metadata": {},
   "source": [
    "## Launch a GPU Kubernetes cluster \n",
    "\n",
    "To get started we need to launch a Kubernetes cluster with GPUs on Google Kubernetes Engine.\n",
    "\n",
    "### Quickstart\n",
    "\n",
    "```console\n",
    "$ gcloud container clusters create rapids \\\n",
    "  --accelerator type=nvidia-tesla-a100,count=2 --machine-type a2-highgpu-2g \\\n",
    "  --zone us-central1-c --release-channel stable\n",
    "```\n",
    "\n",
    "Then we need to install the NVIDIA drivers.\n",
    "\n",
    "```console\n",
    "$ kubectl apply -f https://raw.githubusercontent.com/GoogleCloudPlatform/container-engine-accelerators/master/nvidia-driver-installer/cos/daemonset-preloaded-latest.yaml\n",
    "daemonset.apps/nvidia-driver-installer created\n",
    "```\n",
    "\n",
    "```{docref} /cloud/gcp/gke\n",
    "For more detailed information on launching GPU powered Kubernetes clusters on Google Cloud see the documentation.\n",
    "```\n",
    "\n",
    "Lastly we need to install the Dask Kubernetes Operator.\n",
    "\n",
    "```console\n",
    "$ helm install --repo https://helm.dask.org --create-namespace -n dask-operator --generate-name dask-kubernetes-operator\n",
    "```\n",
    "\n",
    "```{docref} /tools/kubernetes/dask-operator\n",
    "For more detailed information on using the Dask Kubernetes Operator see the documentation.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a2c10f9",
   "metadata": {},
   "source": [
    "### Install dependencies\n",
    "\n",
    "```{docref} /platforms/kubernetes\n",
    "\n",
    "You may want to start a Jupyter session in the Kubernetes cluster and run this notebook from there for best performance. Check out the [RAPIDS Interactive Notebook on Kubernetes docs](/platforms/kubernetes) for more information and be sure to follow the \"Optional extended notebook configuration\".\n",
    "```\n",
    "\n",
    "To launch our Dask cluster on Kubernetes we will need `dask-kubernetes` and to access data stored on Google Cloud we will need `gcsfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cf93be-4c5e-4fa0-9d09-1a65b5eae0ff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install dask-kubernetes gcsfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7e675f",
   "metadata": {},
   "source": [
    "Import other dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "civil-province",
   "metadata": {},
   "outputs": [],
   "source": [
    "import certifi\n",
    "import cudf\n",
    "import cuml\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "import time\n",
    "import yaml\n",
    "\n",
    "from functools import partial\n",
    "from math import cos, sin, asin, sqrt, pi\n",
    "from tqdm import tqdm\n",
    "from typing import Optional\n",
    "\n",
    "import dask\n",
    "import dask.array as da\n",
    "import dask_cudf\n",
    "\n",
    "from dask.distributed import Client, wait, progress\n",
    "\n",
    "\n",
    "class SimpleTimer:\n",
    "    def __init__(self):\n",
    "        self.start = None\n",
    "        self.end = None\n",
    "        self.elapsed = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = time.perf_counter_ns()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.end = time.perf_counter_ns()\n",
    "        self.elapsed = self.end - self.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "social-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the same RAPIDS image you used for launching the notebook session\n",
    "rapids_image = \"{{rapids_container}}\"\n",
    "# Use the number of worker nodes in your Kubernetes cluster\n",
    "n_workers = 8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d67377b",
   "metadata": {},
   "source": [
    "### Launch a Dask cluster\n",
    "\n",
    "Now we can launch a Dask cluster. \n",
    "\n",
    "```{note}\n",
    "To access our remote data we also need to ensure our Dask workers get `gcsfs` installed at runtime.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-bloom",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_kubernetes.operator import KubeCluster\n",
    "\n",
    "cluster = KubeCluster(\n",
    "    name=\"rapids-dask\",\n",
    "    image=rapids_image,\n",
    "    worker_command=\"dask-cuda-worker\",\n",
    "    n_workers=n_workers,\n",
    "    resources={\"limits\": {\"nvidia.com/gpu\": \"1\"}},\n",
    "    env={\n",
    "        \"DISABLE_JUPYTER\": \"true\",\n",
    "        \"EXTRA_PIP_PACKAGES\": \"gcsfs\",\n",
    "    },\n",
    ")\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd614c21-e262-4fcb-b832-6ae35c08726c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-4d81ad0a-a7b5-11ed-8118-2ae434e25e51</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_kubernetes.KubeCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"/proxy/rapids-dask-scheduler.default:8787/status\" target=\"_blank\">/proxy/rapids-dask-scheduler.default:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <button style=\"margin-bottom: 12px;\" data-commandlinker-command=\"dask:populate-and-launch-layout\" data-commandlinker-args='{\"url\": \"/proxy/rapids-dask-scheduler.default:8787/status\" }'>\n",
       "                Launch dashboard in JupyterLab\n",
       "            </button>\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">KubeCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">rapids-dask</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"/proxy/rapids-dask-scheduler.default:8787/status\" target=\"_blank\">/proxy/rapids-dask-scheduler.default:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 8\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 8\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 1.31 TiB\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-9f8afc3d-e159-4160-b316-ec70311df16f</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://10.60.3.8:8786\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 8\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"/proxy/10.60.3.8:8787/status\" target=\"_blank\">/proxy/10.60.3.8:8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 8\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 1.31 TiB\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: rapids-dask-default-worker-0e4c8039c4</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://10.60.1.9:45975\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"/proxy/10.60.1.9:38593/status\" target=\"_blank\">/proxy/10.60.1.9:38593/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 167.06 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://10.60.1.9:34683\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-worker-space/worker-7w4cyatf\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU: </strong>NVIDIA A100-SXM4-40GB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU memory: </strong> 40.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: rapids-dask-default-worker-1e84fcd938</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://10.60.2.12:42063\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"/proxy/10.60.2.12:34049/status\" target=\"_blank\">/proxy/10.60.2.12:34049/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 167.06 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://10.60.2.12:34465\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-worker-space/worker-gcbyo7k5\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU: </strong>NVIDIA A100-SXM4-40GB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU memory: </strong> 40.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: rapids-dask-default-worker-2b53ca2709</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://10.60.0.12:34505\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"/proxy/10.60.0.12:42219/status\" target=\"_blank\">/proxy/10.60.0.12:42219/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 167.06 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://10.60.0.12:36685\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-worker-space/worker-j4wcnc_v\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU: </strong>NVIDIA A100-SXM4-40GB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU memory: </strong> 40.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: rapids-dask-default-worker-7be5028af6</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://10.60.1.10:34633\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"/proxy/10.60.1.10:44177/status\" target=\"_blank\">/proxy/10.60.1.10:44177/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 167.06 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://10.60.1.10:33419\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-worker-space/worker-5josy__1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU: </strong>NVIDIA A100-SXM4-40GB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU memory: </strong> 40.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: rapids-dask-default-worker-7ecd6f55fd</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://10.60.3.9:46121\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"/proxy/10.60.3.9:44263/status\" target=\"_blank\">/proxy/10.60.3.9:44263/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 167.06 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://10.60.3.9:41759\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-worker-space/worker-lyvallm2\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU: </strong>NVIDIA A100-SXM4-40GB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU memory: </strong> 40.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: rapids-dask-default-worker-9684637ac6</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://10.60.2.11:42033\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"/proxy/10.60.2.11:41987/status\" target=\"_blank\">/proxy/10.60.2.11:41987/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 167.06 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://10.60.2.11:35727\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-worker-space/worker-x6224oti\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU: </strong>NVIDIA A100-SXM4-40GB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU memory: </strong> 40.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: rapids-dask-default-worker-9ee4777ca9</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://10.60.4.8:44073\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"/proxy/10.60.4.8:34829/status\" target=\"_blank\">/proxy/10.60.4.8:34829/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 167.06 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://10.60.4.8:34999\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-worker-space/worker-pjkg8s9l\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU: </strong>NVIDIA A100-SXM4-40GB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU memory: </strong> 40.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: rapids-dask-default-worker-ac9c817acd</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://10.60.4.9:38427\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"/proxy/10.60.4.9:41555/status\" target=\"_blank\">/proxy/10.60.4.9:41555/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 167.06 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://10.60.4.9:42793\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-worker-space/worker-qjinfe5i\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU: </strong>NVIDIA A100-SXM4-40GB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU memory: </strong> 40.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.60.3.8:8786' processes=8 threads=8, memory=1.31 TiB>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "clinical-theater",
   "metadata": {},
   "source": [
    "## Helper Tools\n",
    "\n",
    "Define some helper functions for use when exploring `cuML`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "strong-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_workers(client, n_workers, timeout=300):\n",
    "    client.cluster.scale(n_workers)\n",
    "\n",
    "    m = len(client.has_what().keys())\n",
    "    start = end = time.perf_counter_ns()\n",
    "    while (m != n_workers) and (((end - start) / 1e9) < timeout):\n",
    "        time.sleep(5)\n",
    "        m = len(client.has_what().keys())\n",
    "\n",
    "        end = time.perf_counter_ns()\n",
    "\n",
    "    if ((end - start) / 1e9) >= timeout:\n",
    "        raise RuntimeError(\n",
    "            f\"Failed to rescale cluster in {timeout} sec.\"\n",
    "            \"Try increasing timeout for very large containers, and verify available compute resources.\"\n",
    "        )\n",
    "\n",
    "\n",
    "def construct_worker_pool(client, n_workers, auto_scale=False, timeout=300):\n",
    "    workers = [w for w in client.has_what().keys()]\n",
    "    if len(workers) < n_workers:\n",
    "        if auto_scale:\n",
    "            scale_workers(client=client, n_workers=n_workers, timeout=timeout)\n",
    "            workers = [w for w in client.has_what().keys()]\n",
    "        else:\n",
    "            print(\n",
    "                \"Attempt to construct worker pool larger than available worker set, and auto_scale is False.\"\n",
    "                \" Returning entire pool.\"\n",
    "            )\n",
    "    else:\n",
    "        workers = random.sample(population=workers, k=n_workers)\n",
    "\n",
    "    return workers\n",
    "\n",
    "\n",
    "def estimate_df_rows(client, files, storage_opts={}, testpct=0.01):\n",
    "    workers = client.has_what().keys()\n",
    "\n",
    "    est_size = 0\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            df = dask_cudf.read_csv(\n",
    "                file, npartitions=len(workers), storage_options=storage_opts\n",
    "            )\n",
    "        elif file.endswith(\".parquet\"):\n",
    "            df = dask_cudf.read_parquet(\n",
    "                file, npartitions=len(workers), storage_options=storage_opts\n",
    "            )\n",
    "\n",
    "        # Select only the index column from our subsample\n",
    "        est_size += (df.sample(frac=testpct).iloc[:, 0].shape[0] / testpct).compute()\n",
    "        del df\n",
    "\n",
    "    return est_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-debut",
   "metadata": {},
   "source": [
    "### Taxi Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "removable-prefix",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df_part, remap, must_haves):\n",
    "    \"\"\"\n",
    "    This function performs the various clean up tasks for the data\n",
    "    and returns the cleaned dataframe.\n",
    "    \"\"\"\n",
    "    tmp = {col: col.strip().lower() for col in list(df_part.columns)}\n",
    "    df_part = df_part.rename(columns=tmp)\n",
    "\n",
    "    # rename using the supplied mapping\n",
    "    df_part = df_part.rename(columns=remap)\n",
    "\n",
    "    # iterate through columns in this df partition\n",
    "    for col in df_part.columns:\n",
    "        # drop anything not in our expected list\n",
    "        if col not in must_haves:\n",
    "            df_part = df_part.drop(col, axis=1)\n",
    "            continue\n",
    "\n",
    "        # fixes datetime error found by Ty Mckercher and fixed by Paul Mahler\n",
    "        if df_part[col].dtype == \"object\" and col in [\n",
    "            \"pickup_datetime\",\n",
    "            \"dropoff_datetime\",\n",
    "        ]:\n",
    "            df_part[col] = df_part[col].astype(\"datetime64[ms]\")\n",
    "            continue\n",
    "\n",
    "        # if column was read as a string, recast as float\n",
    "        if df_part[col].dtype == \"object\":\n",
    "            df_part[col] = df_part[col].astype(\"float32\")\n",
    "        else:\n",
    "            # downcast from 64bit to 32bit types\n",
    "            # Tesla T4 are faster on 32bit ops\n",
    "            if \"int\" in str(df_part[col].dtype):\n",
    "                df_part[col] = df_part[col].astype(\"int32\")\n",
    "            if \"float\" in str(df_part[col].dtype):\n",
    "                df_part[col] = df_part[col].astype(\"float32\")\n",
    "            df_part[col] = df_part[col].fillna(-1)\n",
    "\n",
    "    return df_part\n",
    "\n",
    "\n",
    "def coalesce_taxi_data(fraction, random_state):\n",
    "    base_path = \"gcs://anaconda-public-data/nyc-taxi/csv\"\n",
    "\n",
    "    # list of column names that need to be re-mapped\n",
    "    remap = {}\n",
    "    remap[\"tpep_pickup_datetime\"] = \"pickup_datetime\"\n",
    "    remap[\"tpep_dropoff_datetime\"] = \"dropoff_datetime\"\n",
    "    remap[\"ratecodeid\"] = \"rate_code\"\n",
    "\n",
    "    # create a list of columns & dtypes the df must have\n",
    "    must_haves = {\n",
    "        \"pickup_datetime\": \"datetime64[ms]\",\n",
    "        \"dropoff_datetime\": \"datetime64[ms]\",\n",
    "        \"passenger_count\": \"int32\",\n",
    "        \"trip_distance\": \"float32\",\n",
    "        \"pickup_longitude\": \"float32\",\n",
    "        \"pickup_latitude\": \"float32\",\n",
    "        \"rate_code\": \"int32\",\n",
    "        \"dropoff_longitude\": \"float32\",\n",
    "        \"dropoff_latitude\": \"float32\",\n",
    "        \"fare_amount\": \"float32\",\n",
    "    }\n",
    "\n",
    "    # apply a list of filter conditions to throw out records with missing or outlier values\n",
    "    query_frags = [\n",
    "        \"fare_amount > 0 and fare_amount < 500\",\n",
    "        \"passenger_count > 0 and passenger_count < 6\",\n",
    "        \"pickup_longitude > -75 and pickup_longitude < -73\",\n",
    "        \"dropoff_longitude > -75 and dropoff_longitude < -73\",\n",
    "        \"pickup_latitude > 40 and pickup_latitude < 42\",\n",
    "        \"dropoff_latitude > 40 and dropoff_latitude < 42\",\n",
    "    ]\n",
    "\n",
    "    valid_months_2016 = [str(x).rjust(2, \"0\") for x in range(1, 7)]\n",
    "    valid_files_2016 = [\n",
    "        f\"{base_path}/2016/yellow_tripdata_2016-{month}.csv\"\n",
    "        for month in valid_months_2016\n",
    "    ]\n",
    "\n",
    "    df_2014_fractional = dask_cudf.read_csv(\n",
    "        f\"{base_path}/2014/yellow_*.csv\", chunksize=25e6\n",
    "    ).sample(frac=fraction, random_state=random_state)\n",
    "    df_2014_fractional = clean(df_2014_fractional, remap, must_haves)\n",
    "\n",
    "    df_2015_fractional = dask_cudf.read_csv(\n",
    "        f\"{base_path}/2015/yellow_*.csv\", chunksize=25e6\n",
    "    ).sample(frac=fraction, random_state=random_state)\n",
    "    df_2015_fractional = clean(df_2015_fractional, remap, must_haves)\n",
    "\n",
    "    df_2016_fractional = dask_cudf.read_csv(valid_files_2016, chunksize=25e6).sample(\n",
    "        frac=fraction, random_state=random_state\n",
    "    )\n",
    "    df_2016_fractional = clean(df_2016_fractional, remap, must_haves)\n",
    "\n",
    "    df_taxi = dask.dataframe.multi.concat(\n",
    "        [df_2014_fractional, df_2015_fractional, df_2016_fractional]\n",
    "    )\n",
    "    df_taxi = df_taxi.query(\" and \".join(query_frags))\n",
    "\n",
    "    return df_taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "exclusive-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def taxi_csv_data_loader(\n",
    "    client, response_dtype=np.float32, fraction=1.0, random_state=0\n",
    "):\n",
    "    response_id = \"fare_amount\"\n",
    "    workers = client.has_what().keys()\n",
    "    km_fields = [\n",
    "        \"passenger_count\",\n",
    "        \"trip_distance\",\n",
    "        \"pickup_longitude\",\n",
    "        \"pickup_latitude\",\n",
    "        \"rate_code\",\n",
    "        \"dropoff_longitude\",\n",
    "        \"dropoff_latitude\",\n",
    "        \"fare_amount\",\n",
    "    ]\n",
    "\n",
    "    taxi_df = coalesce_taxi_data(fraction=fraction, random_state=random_state)\n",
    "\n",
    "    taxi_df = taxi_df[km_fields]\n",
    "    with dask.annotate(workers=set(workers)):\n",
    "        taxi_df = client.persist(collections=taxi_df)\n",
    "\n",
    "    X = taxi_df[taxi_df.columns.difference([response_id])].astype(np.float32)\n",
    "    y = taxi_df[response_id].astype(response_dtype)\n",
    "\n",
    "    wait(taxi_df)\n",
    "\n",
    "    return taxi_df, X, y\n",
    "\n",
    "\n",
    "def taxi_parquet_data_loader(\n",
    "    client, response_dtype=np.float32, fraction=1.0, random_state=0\n",
    "):\n",
    "    # list of column names that need to be re-mapped\n",
    "    remap = {}\n",
    "    remap[\"tpep_pickup_datetime\"] = \"pickup_datetime\"\n",
    "    remap[\"tpep_dropoff_datetime\"] = \"dropoff_datetime\"\n",
    "    remap[\"ratecodeid\"] = \"rate_code\"\n",
    "\n",
    "    # create a list of columns & dtypes the df must have\n",
    "    must_haves = {\n",
    "        \"pickup_datetime\": \"datetime64[ms]\",\n",
    "        \"dropoff_datetime\": \"datetime64[ms]\",\n",
    "        \"passenger_count\": \"int32\",\n",
    "        \"trip_distance\": \"float32\",\n",
    "        \"pickup_longitude\": \"float32\",\n",
    "        \"pickup_latitude\": \"float32\",\n",
    "        \"rate_code\": \"int32\",\n",
    "        \"dropoff_longitude\": \"float32\",\n",
    "        \"dropoff_latitude\": \"float32\",\n",
    "        \"fare_amount\": \"float32\",\n",
    "    }\n",
    "\n",
    "    # apply a list of filter conditions to throw out records with missing or outlier values\n",
    "    query_frags = [\n",
    "        \"fare_amount > 0 and fare_amount < 500\",\n",
    "        \"passenger_count > 0 and passenger_count < 6\",\n",
    "        \"pickup_longitude > -75 and pickup_longitude < -73\",\n",
    "        \"dropoff_longitude > -75 and dropoff_longitude < -73\",\n",
    "        \"pickup_latitude > 40 and pickup_latitude < 42\",\n",
    "        \"dropoff_latitude > 40 and dropoff_latitude < 42\",\n",
    "    ]\n",
    "\n",
    "    workers = client.has_what().keys()\n",
    "    taxi_parquet_path = \"gs://anaconda-public-data/nyc-taxi/nyc.parquet\"\n",
    "    response_id = \"fare_amount\"\n",
    "    fields = [\n",
    "        \"passenger_count\",\n",
    "        \"trip_distance\",\n",
    "        \"pickup_longitude\",\n",
    "        \"pickup_latitude\",\n",
    "        \"rate_code\",\n",
    "        \"dropoff_longitude\",\n",
    "        \"dropoff_latitude\",\n",
    "        \"fare_amount\",\n",
    "    ]\n",
    "\n",
    "    taxi_df = dask_cudf.read_parquet(taxi_parquet_path, npartitions=len(workers))\n",
    "    taxi_df = clean(taxi_df, remap, must_haves)\n",
    "    taxi_df = taxi_df.query(\" and \".join(query_frags))\n",
    "    taxi_df = taxi_df[fields]\n",
    "\n",
    "    with dask.annotate(workers=set(workers)):\n",
    "        taxi_df = client.persist(collections=taxi_df)\n",
    "\n",
    "    wait(taxi_df)\n",
    "\n",
    "    X = taxi_df[taxi_df.columns.difference([response_id])].astype(np.float32)\n",
    "    y = taxi_df[response_id].astype(response_dtype)\n",
    "\n",
    "    return taxi_df, X, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ranking-burns",
   "metadata": {},
   "source": [
    "### Performance Validation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "collect-upper",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def record_elapsed_timings_to_df(\n",
    "    df, timings, record_template, type, columns, write_to=None\n",
    "):\n",
    "    records = [\n",
    "        dict(record_template, **{\"sample_index\": i, \"elapsed\": elapsed, \"type\": type})\n",
    "        for i, elapsed in enumerate(timings)\n",
    "    ]\n",
    "\n",
    "    df = cudf.concat([df, cudf.DataFrame(records)], ignore_index=True)\n",
    "\n",
    "    if write_to:\n",
    "        df.to_csv(write_to, columns=columns)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def collect_load_time_samples(\n",
    "    load_func, count, return_final_sample=True, verbose=False\n",
    "):\n",
    "    timings = []\n",
    "    for m in tqdm(range(count)):\n",
    "        with SimpleTimer() as timer:\n",
    "            df, X, y = load_func()\n",
    "        timings.append(timer.elapsed)\n",
    "\n",
    "    if return_final_sample:\n",
    "        return df, X, y, timings\n",
    "\n",
    "    return None, None, None, timings\n",
    "\n",
    "\n",
    "def collect_func_time_samples(func, count, verbose=False):\n",
    "    timings = []\n",
    "    for k in tqdm(range(count)):\n",
    "        with SimpleTimer() as timer:\n",
    "            func()\n",
    "        timings.append(timer.elapsed)\n",
    "\n",
    "    return timings\n",
    "\n",
    "\n",
    "def sweep_fit_func(model, func_id, require_compute, X, y, xy_fit, count):\n",
    "    _fit_func_attr = getattr(model, func_id)\n",
    "    if require_compute:\n",
    "        if xy_fit:\n",
    "            fit_func = partial(lambda X, y: _fit_func_attr(X, y).compute(), X, y)\n",
    "        else:\n",
    "            fit_func = partial(lambda X: _fit_func_attr(X).compute(), X)\n",
    "    else:\n",
    "        if xy_fit:\n",
    "            fit_func = partial(_fit_func_attr, X, y)\n",
    "        else:\n",
    "            fit_func = partial(_fit_func_attr, X)\n",
    "\n",
    "    return collect_func_time_samples(func=fit_func, count=count)\n",
    "\n",
    "\n",
    "def sweep_predict_func(model, func_id, require_compute, X, count):\n",
    "    _predict_func_attr = getattr(model, func_id)\n",
    "    predict_func = partial(lambda X: _predict_func_attr(X).compute(), X)\n",
    "\n",
    "    return collect_func_time_samples(func=predict_func, count=count)\n",
    "\n",
    "\n",
    "def performance_sweep(\n",
    "    client,\n",
    "    model,\n",
    "    data_loader,\n",
    "    hardware_type,\n",
    "    worker_counts=[1],\n",
    "    samples=1,\n",
    "    load_samples=1,\n",
    "    max_data_frac=1.0,\n",
    "    predict_frac=0.05,\n",
    "    scaling_type=\"weak\",\n",
    "    xy_fit=True,\n",
    "    fit_requires_compute=False,\n",
    "    update_workers_in_kwargs=True,\n",
    "    response_dtype=np.float32,\n",
    "    out_path=\"./perf_sweep.csv\",\n",
    "    append_to_existing=False,\n",
    "    model_name=None,\n",
    "    fit_func_id=\"fit\",\n",
    "    predict_func_id=\"predict\",\n",
    "    scaling_denom=None,\n",
    "    model_args={},\n",
    "    model_kwargs={},\n",
    "):\n",
    "    \"\"\"\n",
    "    Primary performance sweep entrypoint.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    client: DASK client associated with the cluster we're interesting in collecting performance data for.\n",
    "\n",
    "    model: Model object on which to gather performance data. This will be created and destroyed,\n",
    "        once for each element of 'worker_counts'\n",
    "\n",
    "    data_loader: arbitrary data loading function that will be called to load the appropriate testing data.\n",
    "        Function that is responsible for loading and returning the data to be used for a given performance run. Function\n",
    "        signature must accept (client, fraction, and random_state). Client should be used to distribute data, and loaders\n",
    "        should utilize fraction and random_state with dask's dataframe.sample method to allow for control of how much data\n",
    "        is loaded.\n",
    "\n",
    "        When called, its return value should be of the form: df, X, y, where df is the full dask_cudf dataframe, X is a\n",
    "        dask_cudf dataframe which contains all explanatory variables that will be passed to the 'fit' function, and y is a\n",
    "        dask_cudf series or dataframe that contains response variables which should be passed to fit/predict as fit(X, y)\n",
    "\n",
    "    hardware_type: indicates the core hardware the current sweep is running on. ex. 'T4', 'V100', 'A100'\n",
    "\n",
    "    worker_counts: List indicating the number of workers that should be swept. Ex [1, 2, 4]\n",
    "        worker counts must fit within the cluster associated with 'client', if the current DASK worker count is different\n",
    "        from what is requested on a given sweep, attempt to automatically scale the worker count. NOTE: this does not\n",
    "        mean we will scale the available cluster nodes, just the number of deployed worker pods.\n",
    "\n",
    "    samples: number of fit/predict samples to record per worker count\n",
    "\n",
    "    load_samples: number of times to sample data loads. This effectively times how long 'data_loader' runs.\n",
    "\n",
    "    max_data_frac: maximum fraction of data to return.\n",
    "        Strong scaling: each run will utilize max_data_frac data.\n",
    "        Weak scaling: each run will utilize (current worker count) / (max worker count) * max_data_frac data.\n",
    "\n",
    "    predict_frac: fraction of training data used to test inference\n",
    "\n",
    "    scaling_type: values can be 'weak' or 'strong' indicating the type of scaling sweep to perform.\n",
    "\n",
    "    xy_fit: indicates whether or not the model's 'fit' function is of the form (X, y), when xy_fit is False, we assume that\n",
    "        fit is of the form (X), as is the case with various unsupervised methods ex. KNN.\n",
    "\n",
    "    fit_requires_compute: False generally, set this to True if the model's 'fit' function requires a corresponding '.compute()'\n",
    "        call to execute the required work.\n",
    "\n",
    "    update_workers_in_kwargs: Some algorithms accept a 'workers' list, much like DASK, and will require their kwargs to have\n",
    "        workers populated. Setting this flag handles this automatically.\n",
    "\n",
    "    response_dtype: defaults to np.float32, some algorithms require another dtype, such as int32\n",
    "\n",
    "    out_path: path where performance data csv should be saved\n",
    "\n",
    "    append_to_existing: When true, append results to an existing csv, otherwise overwrite.\n",
    "\n",
    "    model_name: Override what we output as the model name\n",
    "\n",
    "    fit_func_id: Defaults to 'fit', only set this if the model has a non-standard naming.\n",
    "\n",
    "    predict_func_id: Defaults to 'predict', only set this if the model has a on-standard predict naming.\n",
    "\n",
    "    scaling_denom: (weak scaling) defaults to max(workers) if unset. Specifies the maximum worker count that weak scaling\n",
    "        should scale against. For example, when using 1 worker in a weak scaling sweep, the worker will attempt to\n",
    "        process a fraction of the total data equal to 1/scaling_denom\n",
    "\n",
    "    model_args: args that will be passed to the model's constructor\n",
    "\n",
    "    model_kwargs: keyword args that will be passed to the model's constructor\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    cols = [\n",
    "        \"n_workers\",\n",
    "        \"sample_index\",\n",
    "        \"elapsed\",\n",
    "        \"type\",\n",
    "        \"algorithm\",\n",
    "        \"scaling_type\",\n",
    "        \"data_fraction\",\n",
    "        \"hardware\",\n",
    "    ]\n",
    "    perf_df = cudf.DataFrame(columns=cols)\n",
    "    if append_to_existing:\n",
    "        try:\n",
    "            perf_df = cudf.read_csv(out_path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    model_name = model_name if model_name else str(model)\n",
    "    scaling_denom = scaling_denom if (scaling_denom is not None) else max(worker_counts)\n",
    "    max_data_frac = min(1.0, max_data_frac)\n",
    "\n",
    "    start_msg = f\"Starting {scaling_type}-scaling performance sweep for:\\n\"\n",
    "    start_msg += f\" model      : {model_name}\\n\"\n",
    "    start_msg += f\" data loader: {data_loader}.\\n\"\n",
    "    start_msg += f\"Configuration\\n\"\n",
    "    start_msg += \"==========================\\n\"\n",
    "    start_msg += f\"{'Worker counts':<25} : {worker_counts}\\n\"\n",
    "    start_msg += f\"{'Fit/Predict samples':<25} : {samples}\\n\"\n",
    "    start_msg += f\"{'Data load samples':<25} : {load_samples}\\n\"\n",
    "    start_msg += f\"- {'Max data fraction':<23} : {max_data_frac}\\n\"\n",
    "    start_msg += f\"{'Model fit':<25} : {'X ~ y' if xy_fit else 'X'}\\n\"\n",
    "    start_msg += f\"- {'Response DType':<23} : {response_dtype}\\n\"\n",
    "    start_msg += f\"{'Writing results to':<25} : {out_path}\\n\"\n",
    "    start_msg += (\n",
    "        f\"- {'Method':<23} : {'overwrite' if not append_to_existing else 'append'}\\n\"\n",
    "    )\n",
    "    print(start_msg, flush=True)\n",
    "\n",
    "    for n in worker_counts:\n",
    "        fraction = (\n",
    "            (n / scaling_denom) * max_data_frac\n",
    "            if scaling_type == \"weak\"\n",
    "            else max_data_frac\n",
    "        )\n",
    "        record_template = {\n",
    "            \"n_workers\": n,\n",
    "            \"type\": \"predict\",\n",
    "            \"algorithm\": model_name,\n",
    "            \"scaling_type\": scaling_type,\n",
    "            \"data_fraction\": fraction,\n",
    "            \"hardware\": hardware_type,\n",
    "        }\n",
    "        scale_workers(client, n)\n",
    "\n",
    "        print(f\"Sampling <{load_samples}> load times with {n} workers.\", flush=True)\n",
    "\n",
    "        load_func = partial(\n",
    "            data_loader,\n",
    "            client=client,\n",
    "            response_dtype=response_dtype,\n",
    "            fraction=fraction,\n",
    "            random_state=0,\n",
    "        )\n",
    "        df, X, y, load_timings = collect_load_time_samples(\n",
    "            load_func=load_func, count=load_samples\n",
    "        )\n",
    "\n",
    "        perf_df = record_elapsed_timings_to_df(\n",
    "            df=perf_df,\n",
    "            timings=load_timings,\n",
    "            type=\"load\",\n",
    "            record_template=record_template,\n",
    "            columns=cols,\n",
    "            write_to=out_path,\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"Finished loading <{load_samples}>, samples, to <{n}> workers with a mean time of {np.mean(load_timings)/1e9:0.4f} sec.\",\n",
    "            flush=True,\n",
    "        )\n",
    "        print(\n",
    "            f\"Sweeping {model_name} '{fit_func_id}' with <{n}> workers. Sampling <{samples}> times.\",\n",
    "            flush=True,\n",
    "        )\n",
    "\n",
    "        if update_workers_in_kwargs and \"workers\" in model_kwargs:\n",
    "            model_kwargs[\"workers\"] = workers = list(client.has_what().keys())\n",
    "\n",
    "        m = model(*model_args, **model_kwargs)\n",
    "        if fit_func_id:\n",
    "            fit_timings = sweep_fit_func(\n",
    "                model=m,\n",
    "                func_id=fit_func_id,\n",
    "                require_compute=fit_requires_compute,\n",
    "                X=X,\n",
    "                y=y,\n",
    "                xy_fit=xy_fit,\n",
    "                count=samples,\n",
    "            )\n",
    "\n",
    "            perf_df = record_elapsed_timings_to_df(\n",
    "                df=perf_df,\n",
    "                timings=fit_timings,\n",
    "                type=\"fit\",\n",
    "                record_template=record_template,\n",
    "                columns=cols,\n",
    "                write_to=out_path,\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                f\"Finished gathering <{samples}>, 'fit' samples using <{n}> workers, with a mean time of {np.mean(fit_timings)/1e9:0.4f} sec.\",\n",
    "                flush=True,\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Skipping fit sweep, fit_func_id is None\")\n",
    "\n",
    "        if predict_func_id:\n",
    "            print(\n",
    "                f\"Sweeping {model_name} '{predict_func_id}' with <{n}> workers. Sampling <{samples}> times.\",\n",
    "                flush=True,\n",
    "            )\n",
    "            predict_timings = sweep_predict_func(\n",
    "                model=m,\n",
    "                func_id=predict_func_id,\n",
    "                require_compute=True,\n",
    "                X=X,\n",
    "                count=samples,\n",
    "            )\n",
    "\n",
    "            perf_df = record_elapsed_timings_to_df(\n",
    "                df=perf_df,\n",
    "                timings=predict_timings,\n",
    "                type=\"predict\",\n",
    "                record_template=record_template,\n",
    "                columns=cols,\n",
    "                write_to=out_path,\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                f\"Finished gathering <{samples}>, 'predict' samples using <{n}> workers, with a mean time of {np.mean(predict_timings)/1e9:0.4f} sec.\",\n",
    "                flush=True,\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Skipping inference sweep. predict_func_id is None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-military",
   "metadata": {},
   "source": [
    "### Vis and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fifteen-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_ci(df, fields, groupby):\n",
    "    gbdf = df[fields].groupby(groupby).agg([\"mean\", \"std\", \"count\"])\n",
    "\n",
    "    ci = 1.96 + gbdf[\"elapsed\"][\"std\"] / np.sqrt(gbdf[\"elapsed\"][\"count\"])\n",
    "\n",
    "    ci_df = ci.reset_index()\n",
    "    ci_df[\"ci.low\"] = gbdf[\"elapsed\"].reset_index()[\"mean\"] - ci_df[0]\n",
    "    ci_df[\"ci.high\"] = gbdf[\"elapsed\"].reset_index()[\"mean\"] + ci_df[0]\n",
    "\n",
    "    return ci_df\n",
    "\n",
    "\n",
    "def visualize_csv_data(csv_path):\n",
    "    df = cudf.read_csv(csv_path)\n",
    "\n",
    "    fields = [\"elapsed\", \"elapsed_sec\", \"type\", \"n_workers\", \"hardware\", \"scaling_type\"]\n",
    "    groupby = [\"n_workers\", \"type\", \"hardware\", \"scaling_type\"]\n",
    "    df[\"elapsed_sec\"] = df[\"elapsed\"] / 1e9\n",
    "\n",
    "    ci_df = simple_ci(df, fields, groupby=groupby)\n",
    "\n",
    "    # Rescale to seconds\n",
    "    ci_df[[\"ci.low\", \"ci.high\"]] = ci_df[[\"ci.low\", \"ci.high\"]] / 1e9\n",
    "\n",
    "    # Print confidence intervals\n",
    "    print(\n",
    "        ci_df[[\"hardware\", \"n_workers\", \"type\", \"ci.low\", \"ci.high\"]][\n",
    "            ci_df[\"type\"] != \"load\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.set(rc={\"figure.figsize\": (20, 10)}, font_scale=2)\n",
    "\n",
    "    # Boxplots for elapsed time at each worker count.\n",
    "    plot_df = df[fields][df[fields].type != \"load\"].to_pandas()\n",
    "    ax = sns.catplot(\n",
    "        data=plot_df,\n",
    "        x=\"n_workers\",\n",
    "        y=\"elapsed_sec\",\n",
    "        col=\"type\",\n",
    "        row=\"scaling_type\",\n",
    "        hue=\"hardware\",\n",
    "        kind=\"box\",\n",
    "        height=8,\n",
    "        order=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-biology",
   "metadata": {},
   "source": [
    "### Taxi Data Configuration (Medium)\n",
    "We can use the parquet data from the anaconda public repo here. Which will illustrate how much faster it is to read parquet, and gives us around 150 million rows of data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "angry-madrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to test with Taxi Dataset\n",
    "preload_data = False\n",
    "append_to_existing = True\n",
    "samples = 5\n",
    "load_samples = 1\n",
    "worker_counts = [8]\n",
    "scaling_denom = 8\n",
    "hardware_type = \"A100\"\n",
    "max_data_frac = 1.0\n",
    "scale_type = \"weak\"  # weak | strong\n",
    "out_prefix = \"taxi_medium\"\n",
    "\n",
    "if not preload_data:\n",
    "    data_loader = taxi_parquet_data_loader\n",
    "else:\n",
    "    data = taxi_parquet_data_loader(client, fraction=max_data_frac)\n",
    "    data_loader = lambda client, response_dtype, fraction, random_state: data\n",
    "\n",
    "if not hardware_type:\n",
    "    raise RuntimeError(\n",
    "        \"Please specify the hardware type for this run! ex. (T4, V100, A100)\"\n",
    "    )\n",
    "\n",
    "sweep_kwargs = {\n",
    "    \"append_to_existing\": append_to_existing,\n",
    "    \"samples\": samples,\n",
    "    \"load_samples\": load_samples,\n",
    "    \"worker_counts\": worker_counts,\n",
    "    \"scaling_denom\": scaling_denom,\n",
    "    \"hardware_type\": hardware_type,\n",
    "    \"data_loader\": data_loader,\n",
    "    \"max_data_frac\": max_data_frac,\n",
    "    \"scaling_type\": scale_type,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "vietnamese-drive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146170000.0\n"
     ]
    }
   ],
   "source": [
    "taxi_parquet_path = [\"gs://anaconda-public-data/nyc-taxi/nyc.parquet\"]\n",
    "estimated_rows = estimate_df_rows(client, files=taxi_parquet_path, testpct=0.0001)\n",
    "print(estimated_rows)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "reduced-booth",
   "metadata": {},
   "source": [
    "### Taxi Data Configuration (Large)\n",
    "The largest dataset we'll work with, contains up to 450 million rows of taxi data, stored as CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "operating-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to sweep with the large Taxi Dataset\n",
    "preload_data = True\n",
    "append_to_existing = True\n",
    "samples = 5\n",
    "load_samples = 1\n",
    "worker_counts = [8]\n",
    "scaling_denom = 8\n",
    "hardware_type = \"A100\"\n",
    "data_loader = taxi_csv_data_loader\n",
    "max_data_frac = 1.0\n",
    "scale_type = \"weak\"\n",
    "out_prefix = \"taxi_large\"\n",
    "\n",
    "\n",
    "if not preload_data:\n",
    "    data_loader = taxi_csv_data_loader\n",
    "else:\n",
    "    data = taxi_csv_data_loader(client, fraction=max_data_frac)\n",
    "    data_loader = lambda client, response_dtype, fraction, random_state: data\n",
    "\n",
    "if not hardware_type:\n",
    "    raise RuntimeError(\n",
    "        \"Please specify the hardware type for this run! ex. (T4, V100, A100)\"\n",
    "    )\n",
    "\n",
    "sweep_kwargs = {\n",
    "    \"append_to_existing\": append_to_existing,\n",
    "    \"samples\": samples,\n",
    "    \"load_samples\": load_samples,\n",
    "    \"worker_counts\": worker_counts,\n",
    "    \"scaling_denom\": scaling_denom,\n",
    "    \"hardware_type\": hardware_type,\n",
    "    \"data_loader\": data_loader,\n",
    "    \"max_data_frac\": max_data_frac,\n",
    "    \"scaling_type\": scale_type,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "romantic-moore",
   "metadata": {},
   "source": [
    "## ETL Exploration CSV vs Parquet\n",
    "\n",
    "Let's load in some data from Google Cloud Storage in both CSV and Parquet and compare the performance differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecological-morris",
   "metadata": {},
   "outputs": [],
   "source": [
    "remap = {}\n",
    "remap[\"tpep_pickup_datetime\"] = \"pickup_datetime\"\n",
    "remap[\"tpep_dropoff_datetime\"] = \"dropoff_datetime\"\n",
    "remap[\"ratecodeid\"] = \"rate_code\"\n",
    "\n",
    "# create a list of columns & dtypes the df must have\n",
    "must_haves = {\n",
    "    \"pickup_datetime\": \"datetime64[ms]\",\n",
    "    \"dropoff_datetime\": \"datetime64[ms]\",\n",
    "    \"passenger_count\": \"int32\",\n",
    "    \"trip_distance\": \"float32\",\n",
    "    \"pickup_longitude\": \"float32\",\n",
    "    \"pickup_latitude\": \"float32\",\n",
    "    \"rate_code\": \"int32\",\n",
    "    \"dropoff_longitude\": \"float32\",\n",
    "    \"dropoff_latitude\": \"float32\",\n",
    "    \"fare_amount\": \"float32\",\n",
    "}\n",
    "\n",
    "# apply a list of filter conditions to throw out records with missing or outlier values\n",
    "query_frags = [\n",
    "    \"fare_amount > 0 and fare_amount < 500\",\n",
    "    \"passenger_count > 0 and passenger_count < 6\",\n",
    "    \"pickup_longitude > -75 and pickup_longitude < -73\",\n",
    "    \"dropoff_longitude > -75 and dropoff_longitude < -73\",\n",
    "    \"pickup_latitude > 40 and pickup_latitude < 42\",\n",
    "    \"dropoff_latitude > 40 and dropoff_latitude < 42\",\n",
    "]\n",
    "\n",
    "workers = client.has_what().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "skilled-apache",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pickup_datetime', 'dropoff_datetime', 'passenger_count',\n",
      "       'trip_distance', 'pickup_longitude', 'pickup_latitude', 'rate_code',\n",
      "       'dropoff_longitude', 'dropoff_latitude', 'fare_amount'],\n",
      "      dtype='object')\n",
      "CSV load took 105.232076116 sec. For 155485869 rows of data => 1477552.0424837382 rows/sec\n"
     ]
    }
   ],
   "source": [
    "base_path = \"gcs://anaconda-public-data/nyc-taxi/csv\"\n",
    "\n",
    "with SimpleTimer() as timer_csv:\n",
    "    df_csv_2014 = dask_cudf.read_csv(\n",
    "        f\"{base_path}/2014/yellow_*.csv\",\n",
    "        chunksize=25e6,\n",
    "        dtype={\" tolls_amount\": \"float64\"},\n",
    "    )\n",
    "    df_csv_2014 = clean(df_csv_2014, remap, must_haves)\n",
    "    df_csv_2014 = df_csv_2014.query(\" and \".join(query_frags))\n",
    "\n",
    "    with dask.annotate(workers=set(workers)):\n",
    "        df_csv_2014 = client.persist(collections=df_csv_2014)\n",
    "\n",
    "    wait(df_csv_2014)\n",
    "\n",
    "print(df_csv_2014.columns)\n",
    "rows_csv = df_csv_2014.iloc[:, 0].shape[0].compute()\n",
    "print(\n",
    "    f\"CSV load took {timer_csv.elapsed/1e9} sec. For {rows_csv} rows of data => {rows_csv/(timer_csv.elapsed/1e9)} rows/sec\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "vertical-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.cancel(df_csv_2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "nutritional-driver",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.9/site-packages/dask/dataframe/io/parquet/core.py:371: FutureWarning: The `chunksize` argument will be deprecated in the future. Please use `split_row_groups` to specify how many row-groups should be mapped to each output partition.\n",
      "\n",
      "If you strongly oppose the deprecation of `chunksize`, please comment at https://github.com/dask/dask/issues/9043\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['dropoff_datetime', 'passenger_count', 'trip_distance',\n",
      "       'pickup_longitude', 'pickup_latitude', 'rate_code', 'dropoff_longitude',\n",
      "       'dropoff_latitude', 'fare_amount'],\n",
      "      dtype='object')\n",
      "Parquet load took 33.298469504 sec. For 138367618 rows of data => 4155374.7082393225 rows/sec\n"
     ]
    }
   ],
   "source": [
    "with SimpleTimer() as timer_parquet:\n",
    "    df_parquet = dask_cudf.read_parquet(\n",
    "        f\"gs://anaconda-public-data/nyc-taxi/nyc.parquet\", chunksize=25e6\n",
    "    )\n",
    "    df_parquet = clean(df_parquet, remap, must_haves)\n",
    "    df_parquet = df_parquet.query(\" and \".join(query_frags))\n",
    "\n",
    "    with dask.annotate(workers=set(workers)):\n",
    "        df_parquet = client.persist(collections=df_parquet)\n",
    "\n",
    "    wait(df_parquet)\n",
    "\n",
    "print(df_parquet.columns)\n",
    "rows_parquet = df_parquet.iloc[:, 0].shape[0].compute()\n",
    "print(\n",
    "    f\"Parquet load took {timer_parquet.elapsed/1e9} sec. For {rows_parquet} rows of data => {rows_parquet/(timer_parquet.elapsed/1e9)} rows/sec\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "spiritual-compilation",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.cancel(df_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ordered-rapid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.812337290843721\n"
     ]
    }
   ],
   "source": [
    "speedup = (rows_parquet / (timer_parquet.elapsed / 1e9)) / (\n",
    "    rows_csv / (timer_csv.elapsed / 1e9)\n",
    ")\n",
    "print(speedup)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "spare-maintenance",
   "metadata": {},
   "source": [
    "## cuML Algorithms -- Performance Sweeps\n",
    "\n",
    "Now let's explore the performance of running various algorithms from `cuML`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-folder",
   "metadata": {},
   "source": [
    "### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-bryan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.dask.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_kwargs = {\"workers\": client.has_what().keys(), \"n_estimators\": 10, \"max_depth\": 12}\n",
    "rf_csv_path = f\"./{out_prefix}_random_forest_regression.csv\"\n",
    "\n",
    "performance_sweep(\n",
    "    client=client,\n",
    "    model=RandomForestRegressor,\n",
    "    **sweep_kwargs,\n",
    "    out_path=rf_csv_path,\n",
    "    response_dtype=np.int32,\n",
    "    model_kwargs=rf_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-madison",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_csv_path = f\"./{out_prefix}_random_forest_regression.csv\"\n",
    "visualize_csv_data(rf_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-hardwood",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.dask.cluster import KMeans\n",
    "\n",
    "kmeans_kwargs = {\n",
    "    \"client\": client,\n",
    "    \"n_clusters\": 12,\n",
    "    \"max_iter\": 371,\n",
    "    \"tol\": 1e-5,\n",
    "    \"oversampling_factor\": 3,\n",
    "    \"max_samples_per_batch\": 32768 / 2,\n",
    "    \"verbose\": False,\n",
    "    \"init\": \"random\",\n",
    "}\n",
    "kmeans_csv_path = f\"./{out_prefix}_kmeans.csv\"\n",
    "\n",
    "performance_sweep(\n",
    "    client=client,\n",
    "    model=KMeans,\n",
    "    **sweep_kwargs,\n",
    "    out_path=kmeans_csv_path,\n",
    "    xy_fit=False,\n",
    "    model_kwargs=kmeans_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_csv_data(kmeans_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-recycling",
   "metadata": {},
   "source": [
    "### Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-question",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.dask.neighbors import NearestNeighbors\n",
    "\n",
    "nn_kwargs = {}\n",
    "nn_csv_path = f\"./{out_prefix}_nn.csv\"\n",
    "\n",
    "performance_sweep(\n",
    "    client=client,\n",
    "    model=NearestNeighbors,\n",
    "    **sweep_kwargs,\n",
    "    out_path=nn_csv_path,\n",
    "    xy_fit=False,\n",
    "    predict_func_id=\"get_neighbors\",\n",
    "    model_kwargs=nn_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-court",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_csv_path = f\"./{out_prefix}_nn.csv\"\n",
    "visualize_csv_data(nn_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-casino",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.dask.decomposition import PCA\n",
    "\n",
    "pca_kwargs = {\"client\": client, \"n_components\": 5, \"whiten\": False}\n",
    "pca_csv_path = f\"./{out_prefix}_pca.csv\"\n",
    "\n",
    "performance_sweep(\n",
    "    client=client,\n",
    "    model=PCA,\n",
    "    **sweep_kwargs,\n",
    "    out_path=pca_csv_path,\n",
    "    xy_fit=False,\n",
    "    fit_requires_compute=True,\n",
    "    fit_func_id=\"fit_transform\",\n",
    "    predict_func_id=None,  # PCA has no 'predict' method.\n",
    "    model_kwargs=pca_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_csv_data(pca_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-lover",
   "metadata": {},
   "source": [
    "### TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.dask.decomposition import TruncatedSVD\n",
    "\n",
    "tsvd_kwargs = {\"client\": client, \"n_components\": 5}\n",
    "tsvd_csv_path = f\"./{out_prefix}_tsvd.csv\"\n",
    "\n",
    "performance_sweep(\n",
    "    client=client,\n",
    "    model=TruncatedSVD,\n",
    "    **sweep_kwargs,\n",
    "    out_path=tsvd_csv_path,\n",
    "    xy_fit=False,\n",
    "    fit_requires_compute=True,\n",
    "    fit_func_id=\"fit_transform\",\n",
    "    predict_func_id=None,\n",
    "    model_kwargs=tsvd_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_csv_data(tsvd_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-mining",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.dask.linear_model import LinearRegression\n",
    "\n",
    "lr_kwargs = {\"client\": client, \"algorithm\": \"eig\"}\n",
    "\n",
    "lr_csv_path = f\"./{out_prefix}_linear_regression.csv\"\n",
    "\n",
    "performance_sweep(\n",
    "    client=client,\n",
    "    model=LinearRegression,\n",
    "    **sweep_kwargs,\n",
    "    out_path=lr_csv_path,\n",
    "    model_kwargs=lr_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_csv_data(lr_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-wellington",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-chancellor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.dask.linear_model import Ridge as RidgeRegression\n",
    "\n",
    "ridge_kwargs = {\"client\": client, \"solver\": \"eig\"}\n",
    "\n",
    "ridge_csv_path = f\"./{out_prefix}_ridge_regression.csv\"\n",
    "\n",
    "performance_sweep(\n",
    "    client=client,\n",
    "    model=RidgeRegression,\n",
    "    **sweep_kwargs,\n",
    "    out_path=ridge_csv_path,\n",
    "    model_kwargs=ridge_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_csv_data(ridge_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-weight",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-superintendent",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.dask.linear_model import Lasso as LassoRegression\n",
    "\n",
    "lasso_kwargs = {\"client\": client}\n",
    "\n",
    "lasso_csv_path = f\"./{out_prefix}_lasso_regression.csv\"\n",
    "\n",
    "performance_sweep(\n",
    "    client=client,\n",
    "    model=LassoRegression,\n",
    "    **sweep_kwargs,\n",
    "    out_path=lasso_csv_path,\n",
    "    model_kwargs=lasso_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-champion",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_csv_data(lasso_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-affair",
   "metadata": {},
   "source": [
    "### ElasticNet Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-elements",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.dask.linear_model import ElasticNet as ElasticNetRegression\n",
    "\n",
    "elastic_kwargs = {\n",
    "    \"client\": client,\n",
    "}\n",
    "\n",
    "enr_csv_path = f\"./{out_prefix}_elastic_regression.csv\"\n",
    "\n",
    "performance_sweep(\n",
    "    client=client,\n",
    "    model=ElasticNetRegression,\n",
    "    **sweep_kwargs,\n",
    "    out_path=enr_csv_path,\n",
    "    model_kwargs=elastic_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_csv_data(enr_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-vinyl",
   "metadata": {},
   "source": [
    "### Model Parallel Multi-GPU Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-volleyball",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.dask.solvers import CD\n",
    "\n",
    "cd_kwargs = {}\n",
    "\n",
    "cd_csv_path = f\"./{out_prefix}_mutli_gpu_linear_regression.csv\"\n",
    "\n",
    "performance_sweep(\n",
    "    client=client,\n",
    "    model=CD,\n",
    "    **sweep_kwargs,\n",
    "    out_path=cd_csv_path,\n",
    "    model_kwargs=cd_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_csv_data(cd_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-albany",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xg_args = [client]\n",
    "xg_kwargs = {\n",
    "    \"params\": {\n",
    "        \"tree_method\": \"gpu_hist\",\n",
    "    },\n",
    "    \"num_boost_round\": 100,\n",
    "}\n",
    "\n",
    "xgb_csv_path = f\"./{out_prefix}_xgb.csv\"\n",
    "\n",
    "\n",
    "class XGBProxy:\n",
    "    \"\"\"\n",
    "    Create a simple API wrapper around XGBoost so that it supports the fit/predict workflow.\n",
    "\n",
    "    Parameters\n",
    "    -------------\n",
    "    data_loader: data loader object intended to be used by the performance sweep.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_loader):\n",
    "        self.args = []\n",
    "        self.kwargs = {}\n",
    "        self.data_loader = data_loader\n",
    "        self.trained_model = None\n",
    "\n",
    "    def loader(self, client, response_dtype, fraction, random_state):\n",
    "        \"\"\"\n",
    "        Wrap the data loader method so that it creates a DMatrix from the returned data.\n",
    "        \"\"\"\n",
    "        df, X, y = self.data_loader(client, response_dtype, fraction, random_state)\n",
    "        dmatrix = xgb.dask.DaskDMatrix(client, X, y)\n",
    "\n",
    "        return dmatrix, dmatrix, dmatrix\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Acts as a pseudo init function which initializes our model args.\n",
    "        \"\"\"\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "        return self\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Wrap dask.train, and store the model on our proxy object.\n",
    "        \"\"\"\n",
    "        if self.trained_model:\n",
    "            del self.trained_model\n",
    "\n",
    "        self.trained_model = xgb.dask.train(\n",
    "            *self.args, dtrain=X, evals=[(X, \"train\")], **self.kwargs\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        assert self.trained_model\n",
    "\n",
    "        return xgb.dask.predict(*self.args, self.trained_model, X)\n",
    "\n",
    "\n",
    "xgb_proxy = XGBProxy(data_loader)\n",
    "performance_sweep(\n",
    "    client=client,\n",
    "    model=xgb_proxy,\n",
    "    data_loader=xgb_proxy.loader,\n",
    "    hardware_type=hardware_type,\n",
    "    worker_counts=worker_counts,\n",
    "    samples=samples,\n",
    "    load_samples=load_samples,\n",
    "    max_data_frac=max_data_frac,\n",
    "    scaling_type=scale_type,\n",
    "    out_path=xgb_csv_path,\n",
    "    append_to_existing=append_to_existing,\n",
    "    update_workers_in_kwargs=False,\n",
    "    xy_fit=False,\n",
    "    scaling_denom=scaling_denom,\n",
    "    model_args=xg_args,\n",
    "    model_kwargs=xg_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_csv_data(xgb_csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deployment-docs-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7a54d993f849a0f97fda357a1a3bac7e25a43aff77e618e8d69a4ad36661dba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
